{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.6/site-packages (2.5.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /opt/conda/lib/python3.6/site-packages (from tensorflow) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.17.1)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.5->tensorflow) (1.31.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard~=2.5->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (8.2.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.6/site-packages (0.17.2)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (1.5.4)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (3.3.4)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (8.2.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.15.1 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (1.19.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (2020.9.3)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.6/site-packages (from scikit-image) (2.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Should be finished running at 11:20 am\n",
    "%pip install tensorflow\n",
    "%pip install --upgrade Pillow\n",
    "%pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "o2LiMYuq0f2V"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import random\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import sagemaker\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EgP2sIKD1NsC"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    input_width = 32\n",
    "    input_height = 32\n",
    "\n",
    "\n",
    "    self.net = nn.Sequential()\n",
    "\n",
    "\n",
    "    #Activation map of size: 3 * input_width * input_height\n",
    "    self.net.add_module('cv1', nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding =  1, dilation = 1))\n",
    "\n",
    "    #Activation map of size: 64 * input_widht * input_height\n",
    "    self.net.add_module('r11', nn.ReLU())\n",
    "\n",
    "    #Activation map of size: 64 * input_width * input_height\n",
    "    self.net.add_module('cv2', nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1, dilation = 1))\n",
    "\n",
    "    #Activation map of size 128* input_width * input_height\n",
    "    self.net.add_module('rl2', nn.ReLU())\n",
    "\n",
    "    #Activation map of size: 128 * input_width/2 * input_height/2\n",
    "    self.net.add_module('mp1', nn.MaxPool2d(kernel_size = 2, stride = None, padding = 0, dilation = 1))\n",
    "\n",
    "    #Activation map of size: 128 * input_width/2 * input_height/2\n",
    "    self.net.add_module('cv3', nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 1, dilation = 1))\n",
    "\n",
    "    #Activation map of size: 256 * input_width/2 * input_height/2\n",
    "    self.net.add_module('rl3', nn.ReLU())\n",
    "\n",
    "    #Activation map of size 256 * input_width/2 * input_height /2\n",
    "    self.net.add_module('cv4', nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 1, dilation = 1))\n",
    "\n",
    "    #Activation map of size 512 * input_width/2 * input_height/2\n",
    "    self.net.add_module('rl4', nn.ReLU())\n",
    "\n",
    "    #Activation map of size 512 * input_width/2 * input_height/2\n",
    "    self.net.add_module('mp2', nn.MaxPool2d(kernel_size = 2, stride = None, padding = 0, dilation = 1))\n",
    "\n",
    "    #Activation map of size 512 * input_width/4 * input_height/4\n",
    "    #self.net.add_module('cv5', nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 1, dilation = 1))\n",
    "\n",
    "    #Activation map of size 512 * input_width/4 * input_height/4\n",
    "    #self.net.add_module('rl5', nn.ReLU())\n",
    "\n",
    "    #activation map of size 512 * input_width/4 * input_height/4\n",
    "    #self.net.add_module('cv6', nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1, dilation = 1))\n",
    "\n",
    "    #activation map of size 512 * input_width/4 * input_height/4\n",
    "    #self.net.add_module('rl6', nn.ReLU())\n",
    "\n",
    "\n",
    "\n",
    "    #Multilayer perceptron\n",
    "    self.net.add_module('dp1', nn.Dropout2d(p = 0.25))\n",
    "    self.net.add_module('fl1', nn.Flatten())\n",
    "    self.net.add_module('fc1', nn.Linear(in_features = 771840, out_features = 128))\n",
    "    self.net.add_module('rl7', nn.ReLU())\n",
    "    self.net.add_module('fc2', nn.Linear(in_features = 128, out_features = 4))\n",
    "    self.net.add_module('sm1', nn.LogSoftmax(dim = 1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.net(x.float())\n",
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# Let's define a Loss function\n",
    "\n",
    "lossfun = nn.NLLLoss()  # Use nn.CrossEntropyLoss with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "\n",
    "imgs = datasets.ImageFolder('Data/Padded', transform = transforms.ToTensor())\n",
    "\n",
    "f = open(\"Data/Target/y_target.txt\")\n",
    "\n",
    "PATH = \"Data\"\n",
    "\n",
    "image_path = os.path.join(PATH, 'Resized', '*')\n",
    "image_paths = sorted(glob.glob(image_path)) \n",
    "len(image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 270, 3)\n",
      "(180, 270, 3)\n",
      "(180, 270, 3)\n",
      "(180, 270, 3)\n",
      "(180, 270, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    img = io.imread(image_paths[i])\n",
    "    print(img.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting to make a custom dataset, so that we can use the below training algorthm. \n",
    "\n",
    "class TrashDataset():\n",
    "    def __init__(self, target_vector_file, train, transform = None):\n",
    "        dataset = {}\n",
    "        target_file = open(\"Data/Target/y_target_with_name.txt\", \"r\")\n",
    "        img_name = target_file.readline()\n",
    "        i = 0\n",
    "        classifications = []\n",
    "        img_names = []\n",
    "        while(img_name != \"\"):\n",
    "            img_names.append(str(img_name).strip())\n",
    "            classifications.append(str(target_file.readline()).strip())\n",
    "            img_name = target_file.readline()\n",
    "        target_file.close()\n",
    "        \n",
    "        dataset = []\n",
    "        \n",
    "        for i in range(len(img_names)):\n",
    "            dataset.append( (img_names[i], classifications[i]))\n",
    "        \n",
    "        self.dataframe = pd.DataFrame(dataset)\n",
    "        self.dataframe = self.dataframe.sample(frac = 1, random_state = 42)\n",
    "        \n",
    "        if train:\n",
    "            self.dataframe = self.dataframe.head(771)\n",
    "        \n",
    "        else:\n",
    "            self.dataframe = self.dataframe.tail(193)\n",
    "            \n",
    "        print(self.dataframe)\n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__ (self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            idx = idx.tolist(index)\n",
    "        img_name = self.dataframe.iloc[index, 0]\n",
    "        img = io.imread(\"Data/Resized/\" + img_name[:-5] + \".jpg\")\n",
    "        classification = self.dataframe.iloc[index, 1]\n",
    "        sample = {\"image\": img, \"classification\": classification}\n",
    "        sample = self.transform(sample)\n",
    "        return sample\n",
    "        \n",
    "\n",
    "        \n",
    "class ToTensor(object):\n",
    "    #Class to turn nparrays to tensor\n",
    "    def __call__(self, sample):\n",
    "        image, classification= sample[\"image\"], sample[\"classification\"]\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {\"image\": torch.from_numpy(image), \"classification\": int(classification)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     0  1\n",
      "760  fe15319d-7d89-4df6-82e5-52b4f6c001af_fa3cba4e-...  2\n",
      "884  ff4e61c6-96aa-4b02-aa12-1b7b5881bfb0_a821fad2-...  2\n",
      "938  ffc6ade2-5bc5-45ce-90aa-d78b591e1b9d_2d5a0bdd-...  2\n",
      "901  ff6d9c14-1b58-46eb-a133-1c36b9b7f675_c9be3801-...  1\n",
      "622  5e9875ff-4b9a-4b90-b190-05bf6c2aa0ac_b23a4bc2-...  2\n",
      "..                                                 ... ..\n",
      "619  5e932284-4d4e-4fca-aef0-ad901d0792ee_448f8405-...  2\n",
      "823  feac2bb4-ee0a-463c-86c6-9eb76a015124_365d330f-...  1\n",
      "645  5ed1a95e-da7a-46d9-afb3-6920244b439c_80c9f4e3-...  1\n",
      "866  ff1fd6bd-69e7-4ebf-a938-9b6aff1c4628_b083732a-...  1\n",
      "556  5ded1e7d-b110-4969-898c-5437201eba56_599786ed-...  1\n",
      "\n",
      "[771 rows x 2 columns]\n",
      "                                                     0  1\n",
      "922  ff931781-06e1-41d7-8420-81191ae1b597_528807fd-...  2\n",
      "577  5e10cede-14d2-45a4-914f-8a13c146425e_9444fe23-...  1\n",
      "85   1c29a97b-794d-4402-b358-572dd8dab846_08205073-...  1\n",
      "242  5aa36e28-c878-4ae5-ac9a-598319f4751d_15e245ac-...  3\n",
      "698  5f55ed58-44ff-4284-824b-f38eaa639ded_1ec62d2b-...  3\n",
      "..                                                 ... ..\n",
      "106  2a1e2bd4-aa0e-40a9-abc4-815ffcba194e_ac294f87-...  2\n",
      "270  5b07380c-9001-4af6-9b38-5db3d874e48c_7353dfd4-...  2\n",
      "860  ff199077-75d8-4c07-a770-370e2b5e24c3_ecdc6aaa-...  1\n",
      "435  5ccf7ba5-d157-48c7-b246-4de35647a777_f29148dc-...  2\n",
      "102  1f5f7413-f78a-4cb6-b8e6-84e7730af9d0_3a1bb18e-...  1\n",
      "\n",
      "[193 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TrashDataset(\"Data/Target/y_target_with_name.txt\", train = True, transform = ToTensor())\n",
    "test_dataset = TrashDataset(\"Data/Target/y_target_with_name.txt\", train = False, transform = ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3-pJZfx8PIKd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-06-17 01:37:59.799 pytorch-1-6-gpu-py3-ml-m5-12xlarge-7d7e51df9510cb050180ece741a1:35 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-06-17 01:37:59.825 pytorch-1-6-gpu-py3-ml-m5-12xlarge-7d7e51df9510cb050180ece741a1:35 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Train Epoch: 1 [0/771 (0%)]\tLoss: 1.816106\tAccuracy: 0.12\n",
      "Train Epoch: 1 [384/771 (48%)]\tLoss: 18.908144\tAccuracy: 0.28\n",
      "Train Epoch: 1 [72/771 (96%)]\tLoss: 1.181961\tAccuracy: 0.33\n",
      "Train Epoch: 1\tAverage Loss: 35118782943.134315\tAverage Accuracy: 0.32\n",
      "Train Epoch: 2 [0/771 (0%)]\tLoss: 1.223186\tAccuracy: 0.28\n",
      "Train Epoch: 2 [384/771 (48%)]\tLoss: 1.335196\tAccuracy: 0.22\n",
      "Train Epoch: 2 [72/771 (96%)]\tLoss: 1.055981\tAccuracy: 1.00\n",
      "Train Epoch: 2\tAverage Loss: 1.277965\tAverage Accuracy: 0.37\n",
      "Train Epoch: 3 [0/771 (0%)]\tLoss: 1.368985\tAccuracy: 0.28\n",
      "Train Epoch: 3 [384/771 (48%)]\tLoss: 1.305671\tAccuracy: 0.41\n",
      "Train Epoch: 3 [72/771 (96%)]\tLoss: 1.202533\tAccuracy: 0.33\n",
      "Train Epoch: 3\tAverage Loss: 1.286388\tAverage Accuracy: 0.32\n",
      "Train Epoch: 4 [0/771 (0%)]\tLoss: 1.527020\tAccuracy: 0.22\n",
      "Train Epoch: 4 [384/771 (48%)]\tLoss: 1.231253\tAccuracy: 0.38\n",
      "Train Epoch: 4 [72/771 (96%)]\tLoss: 1.190033\tAccuracy: 0.33\n",
      "Train Epoch: 4\tAverage Loss: 1.283660\tAverage Accuracy: 0.30\n",
      "Train Epoch: 5 [0/771 (0%)]\tLoss: 1.208117\tAccuracy: 0.31\n",
      "Train Epoch: 5 [384/771 (48%)]\tLoss: 1.392616\tAccuracy: 0.31\n",
      "Train Epoch: 5 [72/771 (96%)]\tLoss: 1.196399\tAccuracy: 0.33\n",
      "Train Epoch: 5\tAverage Loss: 1.284530\tAverage Accuracy: 0.32\n",
      "Train Epoch: 6 [0/771 (0%)]\tLoss: 1.282142\tAccuracy: 0.25\n",
      "Train Epoch: 6 [384/771 (48%)]\tLoss: 1.316252\tAccuracy: 0.41\n",
      "Train Epoch: 6 [72/771 (96%)]\tLoss: 1.139447\tAccuracy: 0.67\n",
      "Train Epoch: 6\tAverage Loss: 1.281676\tAverage Accuracy: 0.33\n",
      "Train Epoch: 7 [0/771 (0%)]\tLoss: 1.260317\tAccuracy: 0.41\n",
      "Train Epoch: 7 [384/771 (48%)]\tLoss: 1.296759\tAccuracy: 0.38\n",
      "Train Epoch: 7 [72/771 (96%)]\tLoss: 1.287130\tAccuracy: 0.00\n",
      "Train Epoch: 7\tAverage Loss: 1.292271\tAverage Accuracy: 0.32\n",
      "Train Epoch: 8 [0/771 (0%)]\tLoss: 1.262715\tAccuracy: 0.38\n",
      "Train Epoch: 8 [384/771 (48%)]\tLoss: 1.205792\tAccuracy: 0.34\n",
      "Train Epoch: 8 [72/771 (96%)]\tLoss: 1.166134\tAccuracy: 0.67\n",
      "Train Epoch: 8\tAverage Loss: 1.282623\tAverage Accuracy: 0.36\n",
      "Train Epoch: 9 [0/771 (0%)]\tLoss: 1.263218\tAccuracy: 0.41\n",
      "Train Epoch: 9 [384/771 (48%)]\tLoss: 1.219104\tAccuracy: 0.28\n",
      "Train Epoch: 9 [72/771 (96%)]\tLoss: 1.240404\tAccuracy: 0.00\n",
      "Train Epoch: 9\tAverage Loss: 1.285301\tAverage Accuracy: 0.33\n",
      "Train Epoch: 10 [0/771 (0%)]\tLoss: 1.383302\tAccuracy: 0.34\n",
      "Train Epoch: 10 [384/771 (48%)]\tLoss: 1.341910\tAccuracy: 0.28\n",
      "Train Epoch: 10 [72/771 (96%)]\tLoss: 1.076812\tAccuracy: 0.33\n",
      "Train Epoch: 10\tAverage Loss: 1.279968\tAverage Accuracy: 0.35\n",
      "Train Epoch: 11 [0/771 (0%)]\tLoss: 1.333255\tAccuracy: 0.31\n",
      "Train Epoch: 11 [384/771 (48%)]\tLoss: 1.261254\tAccuracy: 0.28\n",
      "Train Epoch: 11 [72/771 (96%)]\tLoss: 1.636417\tAccuracy: 0.33\n",
      "Train Epoch: 11\tAverage Loss: 1.307112\tAverage Accuracy: 0.33\n",
      "Train Epoch: 12 [0/771 (0%)]\tLoss: 1.441914\tAccuracy: 0.19\n",
      "Train Epoch: 12 [384/771 (48%)]\tLoss: 1.174060\tAccuracy: 0.56\n",
      "Train Epoch: 12 [72/771 (96%)]\tLoss: 1.590603\tAccuracy: 0.33\n",
      "Train Epoch: 12\tAverage Loss: 1.301006\tAverage Accuracy: 0.34\n",
      "Train Epoch: 13 [0/771 (0%)]\tLoss: 1.315114\tAccuracy: 0.50\n",
      "Train Epoch: 13 [384/771 (48%)]\tLoss: 1.321815\tAccuracy: 0.25\n",
      "Train Epoch: 13 [72/771 (96%)]\tLoss: 1.205353\tAccuracy: 0.00\n",
      "Train Epoch: 13\tAverage Loss: 1.285051\tAverage Accuracy: 0.31\n",
      "Train Epoch: 14 [0/771 (0%)]\tLoss: 1.349305\tAccuracy: 0.19\n",
      "Train Epoch: 14 [384/771 (48%)]\tLoss: 1.297214\tAccuracy: 0.38\n",
      "Train Epoch: 14 [72/771 (96%)]\tLoss: 1.104519\tAccuracy: 0.00\n",
      "Train Epoch: 14\tAverage Loss: 1.284287\tAverage Accuracy: 0.31\n",
      "Train Epoch: 15 [0/771 (0%)]\tLoss: 1.369198\tAccuracy: 0.34\n",
      "Train Epoch: 15 [384/771 (48%)]\tLoss: 1.220077\tAccuracy: 0.38\n",
      "Train Epoch: 15 [72/771 (96%)]\tLoss: 1.218402\tAccuracy: 0.33\n",
      "Train Epoch: 15\tAverage Loss: 1.290821\tAverage Accuracy: 0.35\n",
      "Train Epoch: 16 [0/771 (0%)]\tLoss: 1.220392\tAccuracy: 0.44\n",
      "Train Epoch: 16 [384/771 (48%)]\tLoss: 1.328621\tAccuracy: 0.41\n",
      "Train Epoch: 16 [72/771 (96%)]\tLoss: 1.471335\tAccuracy: 0.67\n",
      "Train Epoch: 16\tAverage Loss: 1.300466\tAverage Accuracy: 0.35\n",
      "Train Epoch: 17 [0/771 (0%)]\tLoss: 1.269234\tAccuracy: 0.31\n",
      "Train Epoch: 17 [384/771 (48%)]\tLoss: 1.312388\tAccuracy: 0.22\n",
      "Train Epoch: 17 [72/771 (96%)]\tLoss: 1.133048\tAccuracy: 0.67\n",
      "Train Epoch: 17\tAverage Loss: 1.291562\tAverage Accuracy: 0.33\n",
      "Train Epoch: 18 [0/771 (0%)]\tLoss: 1.280279\tAccuracy: 0.31\n",
      "Train Epoch: 18 [384/771 (48%)]\tLoss: 1.134675\tAccuracy: 0.25\n",
      "Train Epoch: 18 [72/771 (96%)]\tLoss: 1.321657\tAccuracy: 0.00\n",
      "Train Epoch: 18\tAverage Loss: 1.287684\tAverage Accuracy: 0.32\n",
      "Train Epoch: 19 [0/771 (0%)]\tLoss: 1.301615\tAccuracy: 0.44\n",
      "Train Epoch: 19 [384/771 (48%)]\tLoss: 1.302600\tAccuracy: 0.34\n",
      "Train Epoch: 19 [72/771 (96%)]\tLoss: 1.564417\tAccuracy: 0.33\n",
      "Train Epoch: 19\tAverage Loss: 1.299060\tAverage Accuracy: 0.34\n",
      "Train Epoch: 20 [0/771 (0%)]\tLoss: 1.229663\tAccuracy: 0.41\n",
      "Train Epoch: 20 [384/771 (48%)]\tLoss: 1.243336\tAccuracy: 0.44\n",
      "Train Epoch: 20 [72/771 (96%)]\tLoss: 1.194305\tAccuracy: 0.33\n",
      "Train Epoch: 20\tAverage Loss: 1.285890\tAverage Accuracy: 0.34\n",
      "Train Epoch: 21 [0/771 (0%)]\tLoss: 1.331642\tAccuracy: 0.44\n",
      "Train Epoch: 21 [384/771 (48%)]\tLoss: 1.375013\tAccuracy: 0.34\n",
      "Train Epoch: 21 [72/771 (96%)]\tLoss: 1.584092\tAccuracy: 0.33\n",
      "Train Epoch: 21\tAverage Loss: 1.294710\tAverage Accuracy: 0.35\n",
      "Train Epoch: 22 [0/771 (0%)]\tLoss: 1.362512\tAccuracy: 0.34\n",
      "Train Epoch: 22 [384/771 (48%)]\tLoss: 1.283797\tAccuracy: 0.38\n",
      "Train Epoch: 22 [72/771 (96%)]\tLoss: 1.664044\tAccuracy: 0.33\n",
      "Train Epoch: 22\tAverage Loss: 1.301188\tAverage Accuracy: 0.35\n",
      "Train Epoch: 23 [0/771 (0%)]\tLoss: 1.372654\tAccuracy: 0.34\n",
      "Train Epoch: 23 [384/771 (48%)]\tLoss: 1.338513\tAccuracy: 0.19\n",
      "Train Epoch: 23 [72/771 (96%)]\tLoss: 1.125478\tAccuracy: 0.00\n",
      "Train Epoch: 23\tAverage Loss: 1.284757\tAverage Accuracy: 0.32\n",
      "Train Epoch: 24 [0/771 (0%)]\tLoss: 1.278191\tAccuracy: 0.28\n",
      "Train Epoch: 24 [384/771 (48%)]\tLoss: 1.153120\tAccuracy: 0.44\n",
      "Train Epoch: 24 [72/771 (96%)]\tLoss: 1.193957\tAccuracy: 0.33\n",
      "Train Epoch: 24\tAverage Loss: 1.300770\tAverage Accuracy: 0.34\n",
      "Train Epoch: 25 [0/771 (0%)]\tLoss: 1.270865\tAccuracy: 0.41\n",
      "Train Epoch: 25 [384/771 (48%)]\tLoss: 1.270007\tAccuracy: 0.47\n",
      "Train Epoch: 25 [72/771 (96%)]\tLoss: 1.186872\tAccuracy: 0.67\n",
      "Train Epoch: 25\tAverage Loss: 1.283986\tAverage Accuracy: 0.36\n",
      "Train Epoch: 26 [0/771 (0%)]\tLoss: 1.273066\tAccuracy: 0.31\n",
      "Train Epoch: 26 [384/771 (48%)]\tLoss: 1.416272\tAccuracy: 0.22\n",
      "Train Epoch: 26 [72/771 (96%)]\tLoss: 1.658597\tAccuracy: 0.33\n",
      "Train Epoch: 26\tAverage Loss: 1.307346\tAverage Accuracy: 0.32\n",
      "Train Epoch: 27 [0/771 (0%)]\tLoss: 1.186081\tAccuracy: 0.41\n",
      "Train Epoch: 27 [384/771 (48%)]\tLoss: 1.241955\tAccuracy: 0.34\n",
      "Train Epoch: 27 [72/771 (96%)]\tLoss: 1.225903\tAccuracy: 0.00\n",
      "Train Epoch: 27\tAverage Loss: 1.290197\tAverage Accuracy: 0.32\n",
      "Train Epoch: 28 [0/771 (0%)]\tLoss: 1.244231\tAccuracy: 0.38\n",
      "Train Epoch: 28 [384/771 (48%)]\tLoss: 1.246789\tAccuracy: 0.44\n",
      "Train Epoch: 28 [72/771 (96%)]\tLoss: 1.319625\tAccuracy: 0.00\n",
      "Train Epoch: 28\tAverage Loss: 1.288807\tAverage Accuracy: 0.33\n",
      "Train Epoch: 29 [0/771 (0%)]\tLoss: 1.367662\tAccuracy: 0.28\n",
      "Train Epoch: 29 [384/771 (48%)]\tLoss: 1.235682\tAccuracy: 0.34\n",
      "Train Epoch: 29 [72/771 (96%)]\tLoss: 1.542304\tAccuracy: 0.33\n",
      "Train Epoch: 29\tAverage Loss: 1.302259\tAverage Accuracy: 0.31\n",
      "Train Epoch: 30 [0/771 (0%)]\tLoss: 1.272457\tAccuracy: 0.41\n",
      "Train Epoch: 30 [384/771 (48%)]\tLoss: 1.265147\tAccuracy: 0.38\n",
      "Train Epoch: 30 [72/771 (96%)]\tLoss: 1.192769\tAccuracy: 0.33\n",
      "Train Epoch: 30\tAverage Loss: 1.285199\tAverage Accuracy: 0.32\n",
      "Train Epoch: 31 [0/771 (0%)]\tLoss: 1.227534\tAccuracy: 0.34\n",
      "Train Epoch: 31 [384/771 (48%)]\tLoss: 1.372489\tAccuracy: 0.31\n",
      "Train Epoch: 31 [72/771 (96%)]\tLoss: 1.385887\tAccuracy: 0.00\n",
      "Train Epoch: 31\tAverage Loss: 1.290653\tAverage Accuracy: 0.33\n",
      "Train Epoch: 32 [0/771 (0%)]\tLoss: 1.186493\tAccuracy: 0.44\n",
      "Train Epoch: 32 [384/771 (48%)]\tLoss: 1.396718\tAccuracy: 0.47\n",
      "Train Epoch: 32 [72/771 (96%)]\tLoss: 1.533428\tAccuracy: 0.33\n",
      "Train Epoch: 32\tAverage Loss: 1.297436\tAverage Accuracy: 0.34\n",
      "Train Epoch: 33 [0/771 (0%)]\tLoss: 1.361059\tAccuracy: 0.28\n",
      "Train Epoch: 33 [384/771 (48%)]\tLoss: 1.314874\tAccuracy: 0.34\n",
      "Train Epoch: 33 [72/771 (96%)]\tLoss: 1.226545\tAccuracy: 0.33\n",
      "Train Epoch: 33\tAverage Loss: 1.289107\tAverage Accuracy: 0.34\n",
      "Train Epoch: 34 [0/771 (0%)]\tLoss: 1.372351\tAccuracy: 0.22\n",
      "Train Epoch: 34 [384/771 (48%)]\tLoss: 1.224754\tAccuracy: 0.25\n",
      "Train Epoch: 34 [72/771 (96%)]\tLoss: 1.097964\tAccuracy: 0.33\n",
      "Train Epoch: 34\tAverage Loss: 1.286319\tAverage Accuracy: 0.32\n",
      "Train Epoch: 35 [0/771 (0%)]\tLoss: 1.223865\tAccuracy: 0.38\n",
      "Train Epoch: 35 [384/771 (48%)]\tLoss: 1.314249\tAccuracy: 0.34\n",
      "Train Epoch: 35 [72/771 (96%)]\tLoss: 1.194297\tAccuracy: 0.33\n",
      "Train Epoch: 35\tAverage Loss: 1.287107\tAverage Accuracy: 0.33\n",
      "Train Epoch: 36 [0/771 (0%)]\tLoss: 1.318200\tAccuracy: 0.19\n",
      "Train Epoch: 36 [384/771 (48%)]\tLoss: 1.200944\tAccuracy: 0.34\n",
      "Train Epoch: 36 [72/771 (96%)]\tLoss: 1.576746\tAccuracy: 0.33\n",
      "Train Epoch: 36\tAverage Loss: 1.296295\tAverage Accuracy: 0.32\n",
      "Train Epoch: 37 [0/771 (0%)]\tLoss: 1.354730\tAccuracy: 0.31\n",
      "Train Epoch: 37 [384/771 (48%)]\tLoss: 1.287766\tAccuracy: 0.22\n",
      "Train Epoch: 37 [72/771 (96%)]\tLoss: 1.367172\tAccuracy: 0.00\n",
      "Train Epoch: 37\tAverage Loss: 1.291008\tAverage Accuracy: 0.33\n",
      "Train Epoch: 38 [0/771 (0%)]\tLoss: 1.316067\tAccuracy: 0.44\n",
      "Train Epoch: 38 [384/771 (48%)]\tLoss: 1.223817\tAccuracy: 0.38\n",
      "Train Epoch: 38 [72/771 (96%)]\tLoss: 1.099430\tAccuracy: 0.33\n",
      "Train Epoch: 38\tAverage Loss: 1.283154\tAverage Accuracy: 0.33\n",
      "Train Epoch: 39 [0/771 (0%)]\tLoss: 1.294383\tAccuracy: 0.34\n",
      "Train Epoch: 39 [384/771 (48%)]\tLoss: 1.389871\tAccuracy: 0.34\n",
      "Train Epoch: 39 [72/771 (96%)]\tLoss: 1.598656\tAccuracy: 0.33\n",
      "Train Epoch: 39\tAverage Loss: 1.297781\tAverage Accuracy: 0.37\n",
      "Train Epoch: 40 [0/771 (0%)]\tLoss: 1.237949\tAccuracy: 0.47\n",
      "Train Epoch: 40 [384/771 (48%)]\tLoss: 1.284555\tAccuracy: 0.41\n",
      "Train Epoch: 40 [72/771 (96%)]\tLoss: 1.717361\tAccuracy: 0.00\n",
      "Train Epoch: 40\tAverage Loss: 1.321701\tAverage Accuracy: 0.31\n",
      "Train Epoch: 41 [0/771 (0%)]\tLoss: 1.364793\tAccuracy: 0.34\n",
      "Train Epoch: 41 [384/771 (48%)]\tLoss: 1.414195\tAccuracy: 0.38\n",
      "Train Epoch: 41 [72/771 (96%)]\tLoss: 1.078804\tAccuracy: 0.67\n",
      "Train Epoch: 41\tAverage Loss: 1.280994\tAverage Accuracy: 0.34\n",
      "Train Epoch: 42 [0/771 (0%)]\tLoss: 1.348515\tAccuracy: 0.28\n",
      "Train Epoch: 42 [384/771 (48%)]\tLoss: 1.400300\tAccuracy: 0.34\n",
      "Train Epoch: 42 [72/771 (96%)]\tLoss: 1.729417\tAccuracy: 0.00\n",
      "Train Epoch: 42\tAverage Loss: 1.304340\tAverage Accuracy: 0.32\n",
      "Train Epoch: 43 [0/771 (0%)]\tLoss: 1.169855\tAccuracy: 0.50\n",
      "Train Epoch: 43 [384/771 (48%)]\tLoss: 1.265515\tAccuracy: 0.28\n",
      "Train Epoch: 43 [72/771 (96%)]\tLoss: 1.601302\tAccuracy: 0.33\n",
      "Train Epoch: 43\tAverage Loss: 1.294200\tAverage Accuracy: 0.33\n",
      "Train Epoch: 44 [0/771 (0%)]\tLoss: 1.290248\tAccuracy: 0.31\n",
      "Train Epoch: 44 [384/771 (48%)]\tLoss: 1.258462\tAccuracy: 0.38\n",
      "Train Epoch: 44 [72/771 (96%)]\tLoss: 1.207523\tAccuracy: 0.33\n",
      "Train Epoch: 44\tAverage Loss: 1.286527\tAverage Accuracy: 0.31\n",
      "Train Epoch: 45 [0/771 (0%)]\tLoss: 1.228830\tAccuracy: 0.31\n",
      "Train Epoch: 45 [384/771 (48%)]\tLoss: 1.309300\tAccuracy: 0.28\n",
      "Train Epoch: 45 [72/771 (96%)]\tLoss: 1.627782\tAccuracy: 0.33\n",
      "Train Epoch: 45\tAverage Loss: 1.304434\tAverage Accuracy: 0.31\n",
      "Train Epoch: 46 [0/771 (0%)]\tLoss: 1.197561\tAccuracy: 0.47\n",
      "Train Epoch: 46 [384/771 (48%)]\tLoss: 1.338738\tAccuracy: 0.31\n",
      "Train Epoch: 46 [72/771 (96%)]\tLoss: 1.040833\tAccuracy: 0.67\n",
      "Train Epoch: 46\tAverage Loss: 1.279554\tAverage Accuracy: 0.36\n",
      "Train Epoch: 47 [0/771 (0%)]\tLoss: 1.421148\tAccuracy: 0.22\n",
      "Train Epoch: 47 [384/771 (48%)]\tLoss: 1.232676\tAccuracy: 0.38\n",
      "Train Epoch: 47 [72/771 (96%)]\tLoss: 1.306898\tAccuracy: 0.33\n",
      "Train Epoch: 47\tAverage Loss: 1.286049\tAverage Accuracy: 0.33\n",
      "Train Epoch: 48 [0/771 (0%)]\tLoss: 1.256584\tAccuracy: 0.34\n",
      "Train Epoch: 48 [384/771 (48%)]\tLoss: 1.220829\tAccuracy: 0.34\n",
      "Train Epoch: 48 [72/771 (96%)]\tLoss: 1.086770\tAccuracy: 0.33\n",
      "Train Epoch: 48\tAverage Loss: 1.283901\tAverage Accuracy: 0.34\n",
      "Train Epoch: 49 [0/771 (0%)]\tLoss: 1.394642\tAccuracy: 0.22\n",
      "Train Epoch: 49 [384/771 (48%)]\tLoss: 1.286819\tAccuracy: 0.34\n",
      "Train Epoch: 49 [72/771 (96%)]\tLoss: 1.155007\tAccuracy: 0.67\n",
      "Train Epoch: 49\tAverage Loss: 1.282235\tAverage Accuracy: 0.34\n",
      "Train Epoch: 50 [0/771 (0%)]\tLoss: 1.183841\tAccuracy: 0.28\n",
      "Train Epoch: 50 [384/771 (48%)]\tLoss: 1.299030\tAccuracy: 0.34\n",
      "Train Epoch: 50 [72/771 (96%)]\tLoss: 1.073675\tAccuracy: 0.67\n",
      "Train Epoch: 50\tAverage Loss: 1.283095\tAverage Accuracy: 0.35\n"
     ]
    }
   ],
   "source": [
    "#Training the model, (here we go!)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True, num_workers = 4)\n",
    "\n",
    "def train(model, train_loader, epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Define train epochs\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "\n",
    "        # iterate through train dataset\n",
    "        epoch_loss = []\n",
    "        epoch_accu = []\n",
    "\n",
    "        for batch_idx, sample in enumerate(train_loader):\n",
    "            \n",
    "            #data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            data = sample[\"image\"]\n",
    "            target = sample[\"classification\"]\n",
    "\n",
    "            #print(data.shape)\n",
    "\n",
    "            # get output\n",
    "            output = model(data)\n",
    "\n",
    "            # compute loss function\n",
    "            loss = lossfun(output, target)\n",
    "\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # run optimizer \n",
    "            optimizer.step()\n",
    "\n",
    "            # bookkeeping\n",
    "            accuracy = (output.argmax(-1) == target).float().mean()\n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_accu.append(accuracy.item())\n",
    "\n",
    "            if batch_idx % 12 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {:.2f}'.format(\n",
    "                    epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item(), accuracy.item()))\n",
    "\n",
    "        print('Train Epoch: {}\\tAverage Loss: {:.6f}\\tAverage Accuracy: {:.2f}'.format(\n",
    "            epoch+1, sum(epoch_loss)/len(epoch_loss), sum(epoch_accu)/len(epoch_accu)))\n",
    "            \n",
    "    # save network\n",
    "    \n",
    "    return epoch_loss, epoch_accu\n",
    "\n",
    "epoch_loss, epoch_accu = train(model, train_loader, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to test...\n",
      "Testing batch index:  0\n",
      "Testing batch index:  1\n",
      "Testing batch index:  2\n",
      "Testing batch index:  3\n",
      "Testing batch index:  4\n",
      "Testing batch index:  5\n",
      "Testing batch index:  6\n",
      "Average Loss: 1.264133\tAverage Accuracy: 0.30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.2168331146240234,\n",
       "  1.2642390727996826,\n",
       "  1.2565412521362305,\n",
       "  1.2239166498184204,\n",
       "  1.306265115737915,\n",
       "  1.4071767330169678,\n",
       "  1.1739568710327148],\n",
       " [0.28125, 0.34375, 0.4375, 0.34375, 0.375, 0.34375, 0.0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test(test_loader):\n",
    "    \n",
    "    total_loss = []\n",
    "    total_accu = []\n",
    "    \n",
    "    print(\"starting to test...\")\n",
    "    \n",
    "    for batch_idx, sample in enumerate(test_loader):\n",
    "        \n",
    "            print(\"Testing batch index: \", batch_idx)\n",
    "            \n",
    "\n",
    "            #data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            data = sample[\"image\"]\n",
    "            target = sample[\"classification\"]\n",
    "\n",
    "            #print(data.shape)\n",
    "\n",
    "            # get output\n",
    "            output = model(data)\n",
    "\n",
    "            # compute loss function\n",
    "            loss = lossfun(output, target)\n",
    "\n",
    "            # bookkeeping\n",
    "            accuracy = (output.argmax(-1) == target).float().mean()\n",
    "            total_loss.append(loss.item())\n",
    "            total_accu.append(accuracy.item())\n",
    "            \n",
    "\n",
    "    print('Average Loss: {:.6f}\\tAverage Accuracy: {:.2f}'.format(\n",
    "            sum(total_loss)/len(total_loss), sum(total_accu)/len(total_accu)))\n",
    "            \n",
    "    \n",
    "    return total_loss, total_accu\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False)\n",
    "\n",
    "test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function get_execution_role at 0x7fabf2415bf8>\n"
     ]
    }
   ],
   "source": [
    "#Train attempt 2\n",
    "\n",
    "#Set up permissions and enviroment variables. \n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role\n",
    "print(role)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = \"e-team6\"\n",
    "prefix = \"ic-fulltraining\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, \"image-classification\", repo_version = \"latest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preperation\n",
    "\n",
    "import boto3 \n",
    "\n",
    "#Function to transfer data to s3 for training. \n",
    "\n",
    "def upload_to_s3(channel, file):\n",
    "    s3 = boto3.resource(\"s3\")\n",
    "    data = open(file, \"rb\")\n",
    "    key = channel + \"/\" + file\n",
    "    s3.Bucket(bucket).put_object(Key = key, Body = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into to channels -- train and test\n",
    "\n",
    "s3train = \"s3://{}/{}/train\".format(bucket, prefix)\n",
    "s3validation = \"s3://{}/{}/validation\".format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upload images into validation and training channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_run has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_volume_size has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "s3_output_location = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "ic = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role, \n",
    "    train_instance_count = 1, \n",
    "    train_instance_type = \"m1.p2.xlarge\",\n",
    "    train_volume_size = 50, \n",
    "    train_max_run = 360000,\n",
    "    input_model = \"file\",\n",
    "    output_path = s3_output_location, \n",
    "    sagemaker_session = sess\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up hyperparmeters in the algorithm.\n",
    "\n",
    "ic.set_hyperparameters(\n",
    "    num_layers = 18, \n",
    "    image_shape = \"3, 5312, 4032\",\n",
    "    num_classes = 4, \n",
    "    num_training_examples = 400,\n",
    "    mini_batch_size = 32,\n",
    "    epochs = 10,\n",
    "    learning_rate = 0.1,\n",
    "    top_k = 2#I have no idea what this parameter does\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3train, \n",
    "    distribution = \"FullyReplicated\",\n",
    "    content_type = \"image/jpeg\",\n",
    "    s3_data_type = \"S3Prefix\",\n",
    "    )\n",
    "\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3validation, \n",
    "    distribution = \"FullyRepliatied\",\n",
    "    content_type = \"image/jpeg\", \n",
    "    s3_data_type = \"S3Prefix\"\n",
    "    )\n",
    "\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "PATH = \"train\"\n",
    "image_path = os.path.join(PATH, 'images', '*')\n",
    "image_paths = sorted(glob.glob(image_path)) \n",
    "\n",
    "for path in image_paths:\n",
    "    upload_to_s3(\"train\", path)\n",
    "    \n",
    "PATH = \"valid\"    \n",
    "image_path = os.path.join(PATH, \"images\", \"*\")\n",
    "imagePaths = sorted(glob.glob(image_path))\n",
    "\n",
    "for path in image_paths:\n",
    "    upload_to_s3(\"validation\", path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'function' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-819888737956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1421\u001b[0m             \u001b[0mall\u001b[0m \u001b[0minformation\u001b[0m \u001b[0mabout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstarted\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m         \"\"\"\n\u001b[0;32m-> 1423\u001b[0;31m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1424\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36m_get_train_args\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1453\u001b[0m                 )\n\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0mcurrent_hyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/job.py\u001b[0m in \u001b[0;36m_load_config\u001b[0;34m(inputs, estimator, expand_role, validate_uri)\u001b[0m\n\u001b[1;32m     68\u001b[0m         role = (\n\u001b[1;32m     69\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mexpand_role\u001b[0;34m(self, role)\u001b[0m\n\u001b[1;32m   3468\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mAWS\u001b[0m \u001b[0mIAM\u001b[0m \u001b[0mrole\u001b[0m \u001b[0mARN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3469\u001b[0m         \"\"\"\n\u001b[0;32m-> 3470\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3471\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3472\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboto_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'function' is not iterable"
     ]
    }
   ],
   "source": [
    "ic.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
